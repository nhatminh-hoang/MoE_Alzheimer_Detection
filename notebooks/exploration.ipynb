{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration\n",
    "\n",
    "This notebook is for exploring and visualizing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/mjnk/Study/MoE_Alzheimer_Detection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pylangacq\n",
    "\n",
    "from tqdm import tqdm\n",
    "import string\n",
    "punctuations = string.punctuation\n",
    "\n",
    "from scripts.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define PATH\n",
    "ADReSS2020_DATAPATH = \"../data/ADReSS-IS2020-data\"\n",
    "ADReSS2020_TRAINPATH = os.path.join(ADReSS2020_DATAPATH, \"train\")\n",
    "ADReSS2020_TESTPATH = os.path.join(ADReSS2020_DATAPATH, \"test\")\n",
    "\n",
    "TRANSCRIPT_NAME = \"transcription\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chat_data(split):\n",
    "    \"\"\"\n",
    "    Get the CHAT data from the ADReSS-IS2020 dataset.\n",
    "    \n",
    "    Parameters:\n",
    "        split (str): The split to load (either \"train\" or \"test\").\n",
    "        data_path (str): The path to the ADReSS-IS2020 dataset.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: A DataFrame containing the CHAT data and labels.\n",
    "    \"\"\"\n",
    "    path = ADReSS2020_TRAINPATH if split == \"train\" else ADReSS2020_TESTPATH\n",
    "    # Define the path to the transcript files.\n",
    "    transcript_path = os.path.join(path, TRANSCRIPT_NAME)\n",
    "    # Read the CHAT data.\n",
    "    reader = pylangacq.read_chat(transcript_path)\n",
    "\n",
    "    file_paths = reader.file_paths()\n",
    "    data = []\n",
    "\n",
    "    test_df = pd.read_csv(ADReSS2020_DATAPATH + '/2020Labels.txt', delimiter=';', skipinitialspace=True)\n",
    "    test_df = test_df.drop(columns=['age', 'mmse', 'gender'], axis=1)\n",
    "\n",
    "    # Read and merge utterances from each file.\n",
    "    for file_path in file_paths:\n",
    "        # Read and merge *PAR utterances.\n",
    "        utterances = read_par_utterances(file_path)\n",
    "\n",
    "        # Tokenize and merge tokens from each utterance.\n",
    "        all_tokens = []\n",
    "        for utt in utterances:\n",
    "            tokens = tokenize_and_merge(utt)\n",
    "            all_tokens.extend([token for token in tokens if token not in list(punctuations)])\n",
    "\n",
    "        if split == 'test':\n",
    "            label = test_df[test_df['ID'] == os.path.basename(file_path).split('.')[0] + ' '].Label.iloc[0]\n",
    "        \n",
    "        elif split == 'train':\n",
    "            label = 0 if 'cc' in file_path else 1\n",
    "\n",
    "        data.append((all_tokens, label))\n",
    "\n",
    "    return pd.DataFrame(data, columns=['tokens', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = get_chat_data('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mjnk/miniconda3/envs/ml/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ModernBertConfig {\n",
       "  \"_attn_implementation_autoset\": true,\n",
       "  \"attention_bias\": false,\n",
       "  \"attention_dropout\": 0.0,\n",
       "  \"bos_token_id\": 50281,\n",
       "  \"classifier_activation\": \"gelu\",\n",
       "  \"classifier_bias\": false,\n",
       "  \"classifier_dropout\": 0.0,\n",
       "  \"classifier_pooling\": \"cls\",\n",
       "  \"cls_token_id\": 50281,\n",
       "  \"decoder_bias\": true,\n",
       "  \"deterministic_flash_attn\": false,\n",
       "  \"embedding_dropout\": 0.0,\n",
       "  \"eos_token_id\": 50282,\n",
       "  \"global_attn_every_n_layers\": 3,\n",
       "  \"global_rope_theta\": 160000.0,\n",
       "  \"hidden_activation\": \"gelu\",\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_cutoff_factor\": 2.0,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 1152,\n",
       "  \"local_attention\": 128,\n",
       "  \"local_rope_theta\": 10000.0,\n",
       "  \"max_position_embeddings\": 8192,\n",
       "  \"mlp_bias\": false,\n",
       "  \"mlp_dropout\": 0.0,\n",
       "  \"model_type\": \"modernbert\",\n",
       "  \"norm_bias\": false,\n",
       "  \"norm_eps\": 1e-05,\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 22,\n",
       "  \"pad_token_id\": 50283,\n",
       "  \"reference_compile\": null,\n",
       "  \"repad_logits_with_grad\": false,\n",
       "  \"sep_token_id\": 50282,\n",
       "  \"sparse_pred_ignore_index\": -100,\n",
       "  \"sparse_prediction\": false,\n",
       "  \"transformers_version\": \"4.50.0.dev0\",\n",
       "  \"vocab_size\": 50368\n",
       "}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import ModernBertModel, ModernBertConfig\n",
    "\n",
    "# Initializing a ModernBert style configuration\n",
    "configuration = ModernBertConfig()\n",
    "\n",
    "# Initializing a model from the modernbert-base style configuration\n",
    "model = ModernBertModel(configuration)\n",
    "\n",
    "# Accessing the model configuration\n",
    "configuration = model.config\n",
    "configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3147, -0.5636, -0.7742,  ..., -0.3935,  0.1778, -0.5275],\n",
       "         [-0.6348, -1.3041,  0.1655,  ..., -0.4116, -1.4177,  0.8489],\n",
       "         [ 0.0905,  0.0599,  0.2130,  ...,  0.1283, -0.0392,  0.0715],\n",
       "         ...,\n",
       "         [-0.2144, -0.9171,  0.2220,  ..., -1.3775, -0.1156,  0.1317],\n",
       "         [ 0.9564, -0.9251,  0.3561,  ..., -0.4667, -0.0707, -0.2410],\n",
       "         [ 0.2560, -0.0717,  0.0984,  ...,  0.0122,  0.0510, -0.1633]]],\n",
       "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, ModernBertModel\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"answerdotai/ModernBERT-base\")\n",
    "model = ModernBertModel.from_pretrained(\"answerdotai/ModernBERT-base\")\n",
    "\n",
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\").to(device)\n",
    "outputs = model.to(device)(**inputs)\n",
    "\n",
    "last_hidden_states = outputs.last_hidden_state\n",
    "last_hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 300])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\" \".join(train_data.iloc[5]['tokens']), \n",
    "          return_tensors='pt', \n",
    "          truncation=True, \n",
    "          padding='max_length', \n",
    "          max_length=300)['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 768])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[50281, 38878,   479,  ..., 50283, 50283, 50283],\n",
       "        [50281,  6309,  1007,  ..., 50283, 50283, 50283],\n",
       "        [50281,   536,   333,  ..., 50283, 50283, 50283],\n",
       "        ...,\n",
       "        [50281, 22659,   285,  ..., 50283, 50283, 50283],\n",
       "        [50281,   536,   333,  ..., 50283, 50283, 50283],\n",
       "        [50281, 22659,  8261,  ..., 50283, 50283, 50283]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(train_data.tokens.apply(\" \".join).to_list(), return_tensors='pt', truncation=True, padding=True, max_length=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutput(last_hidden_state=tensor([[[ 0.3147, -0.5636, -0.7742,  ..., -0.3935,  0.1778, -0.5275],\n",
       "         [-0.6348, -1.3041,  0.1655,  ..., -0.4116, -1.4177,  0.8489],\n",
       "         [ 0.0905,  0.0599,  0.2130,  ...,  0.1283, -0.0392,  0.0715],\n",
       "         ...,\n",
       "         [-0.2144, -0.9171,  0.2220,  ..., -1.3775, -0.1156,  0.1317],\n",
       "         [ 0.9564, -0.9251,  0.3561,  ..., -0.4667, -0.0707, -0.2410],\n",
       "         [ 0.2560, -0.0717,  0.0984,  ...,  0.0122,  0.0510, -0.1633]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 768])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
