{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration\n",
    "\n",
    "This notebook is for exploring and visualizing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define PATH\n",
    "ADReSS2020_DATAPATH = \"../data/ADReSS-IS2020-data\"\n",
    "ADReSS2020_TRAINPATH = os.path.join(ADReSS2020_DATAPATH, \"train\")\n",
    "ADReSS2020_TESTPATH = os.path.join(ADReSS2020_DATAPATH, \"test\")\n",
    "\n",
    "FULL_WAVE_NAME = \"Full_wave_enhanced_audio\"\n",
    "CHUNK_WAVE_NAME = \"Normalised_audio-chunks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Normalised_audio-chunks',\n",
       " 'cd_meta_data.txt',\n",
       " 'cc_meta_data.txt',\n",
       " 'README.md',\n",
       " 'transcription',\n",
       " 'Full_wave_enhanced_audio']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(ADReSS2020_TRAINPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get file paths and labels\n",
    "def get_audio_files_and_labels(dataset_path, split_folder_path, split):\n",
    "    audio_files = []\n",
    "    labels = []\n",
    "\n",
    "    if split == 'train':\n",
    "        for folder in os.listdir(split_folder_path):\n",
    "            folder_path = os.path.join(split_folder_path, folder)\n",
    "            if os.path.isdir(folder_path) and os.path.basename(folder_path) == FULL_WAVE_NAME:\n",
    "                for label in os.listdir(folder_path):\n",
    "                    label_path = os.path.join(folder_path, label)\n",
    "                    if os.path.isdir(label_path):\n",
    "                        for file_name in os.listdir(label_path):\n",
    "                            if file_name.endswith('.wav'):\n",
    "                                audio_files.append(os.path.join(label_path, file_name))\n",
    "                                if label == 'cc':\n",
    "                                    labels.append(0)\n",
    "                                elif label == 'cd':\n",
    "                                    labels.append(1)\n",
    "    \n",
    "    elif split == 'test':\n",
    "        test_df = pd.read_csv(dataset_path + '/2020Labels.txt', delimiter=';', skipinitialspace=True)\n",
    "        test_df = test_df.drop(columns=['age', 'mmse', 'gender'], axis=1)\n",
    "        \n",
    "        for folder in os.listdir(split_folder_path):\n",
    "            folder_path = os.path.join(split_folder_path, folder)\n",
    "            if os.path.isdir(folder_path) and os.path.basename(folder_path) == FULL_WAVE_NAME:\n",
    "                for file_name in os.listdir(folder_path):\n",
    "                    if file_name.endswith('.wav'):\n",
    "                        audio_name = file_name.split('.')[0] + ' '\n",
    "                        audio_files.append(os.path.join(folder_path, file_name))\n",
    "                        labels.append(test_df[test_df['ID'] == audio_name].Label.iloc[0])\n",
    "                        \n",
    "    return audio_files, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108, 108, 48, 48)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load train and test data\n",
    "train_audio_files, train_labels = get_audio_files_and_labels(ADReSS2020_DATAPATH, ADReSS2020_TRAINPATH, split='train')\n",
    "test_audio_files, test_labels = get_audio_files_and_labels(ADReSS2020_DATAPATH, ADReSS2020_TESTPATH, split='test')\n",
    "\n",
    "len(train_audio_files), len(train_labels), len(test_audio_files), len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation Functions\n",
    "def add_noise(data, noise_factor=0.005):\n",
    "    noise = np.random.randn(len(data))\n",
    "    augmented_data = data + noise_factor * noise\n",
    "    return augmented_data\n",
    "\n",
    "def pitch_shift(data, sampling_rate, pitch_factor=2):\n",
    "    return librosa.effects.pitch_shift(data, sr=sampling_rate, n_steps=pitch_factor)\n",
    "\n",
    "def time_stretch(data, rate=0.8):\n",
    "    return librosa.effects.time_stretch(data, rate=rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and augment the audio data\n",
    "def load_and_augment_audio(file_path, label, audio_data, audio_labels):\n",
    "    data, sr = librosa.load(file_path, sr=None)\n",
    "    augmented_data = [\n",
    "        data,\n",
    "        add_noise(data),\n",
    "        pitch_shift(data, sr),\n",
    "        time_stretch(data, 0.9),\n",
    "        time_stretch(data, 1.1)\n",
    "    ]\n",
    "    for aug_data in augmented_data:\n",
    "        audio_data.append(aug_data)\n",
    "        audio_labels.append(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Prepare testing data\n",
    "# audio_data = []\n",
    "# audio_labels = []\n",
    "\n",
    "# for file_path, label in tqdm(zip(test_audio_files, test_labels), total=len(test_audio_files)):\n",
    "#     load_and_augment_audio(file_path, label, audio_data, audio_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 1: 100%|██████████| 10/10 [00:18<00:00,  1.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch with 50 items\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 2: 100%|██████████| 10/10 [00:14<00:00,  1.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch with 50 items\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 3: 100%|██████████| 10/10 [00:19<00:00,  1.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch with 50 items\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 4: 100%|██████████| 10/10 [00:15<00:00,  1.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch with 50 items\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 5: 100%|██████████| 10/10 [00:16<00:00,  1.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch with 50 items\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 6: 100%|██████████| 10/10 [00:22<00:00,  2.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch with 50 items\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 7: 100%|██████████| 10/10 [00:19<00:00,  1.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch with 50 items\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 8: 100%|██████████| 10/10 [00:24<00:00,  2.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch with 50 items\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 9: 100%|██████████| 10/10 [00:22<00:00,  2.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch with 50 items\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 10: 100%|██████████| 10/10 [00:20<00:00,  2.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch with 50 items\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 11: 100%|██████████| 8/8 [00:19<00:00,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch with 40 items\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 10  # Adjust as needed\n",
    "\n",
    "def process_batches(files, labels, batch_size=BATCH_SIZE):\n",
    "    for i in range(0, len(files), batch_size):\n",
    "        batch_files = files[i:i+batch_size]\n",
    "        batch_labels = labels[i:i+batch_size]\n",
    "        batch_audio_data = []\n",
    "        batch_audio_labels = []\n",
    "        for file_path, label in tqdm(zip(batch_files, batch_labels), total=len(batch_files),\n",
    "                                       desc=f\"Processing batch {i//batch_size + 1}\"):\n",
    "            # Reference: [`scripts.utils.load_and_augment_audio`](scripts/utils.py#L130)\n",
    "            load_and_augment_audio(file_path, label, batch_audio_data, batch_audio_labels)\n",
    "        yield batch_audio_data, batch_audio_labels\n",
    "\n",
    "# Usage example in a notebook cell:\n",
    "audio_data = []\n",
    "audio_labels = []\n",
    "\n",
    "for batch_data, batch_labels in process_batches(train_audio_files, train_labels):\n",
    "    # Process each batch (e.g., further pre-processing or saving results)\n",
    "    audio_data.extend(batch_data)\n",
    "    audio_labels.extend(batch_labels)\n",
    "    # Optionally clear variables or process the batch to free memory\n",
    "    print(f\"Processed batch with {len(batch_data)} items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment the audio data into 25-second segments\n",
    "def segment_audio(data, sr, segment_length=25):\n",
    "    segment_samples = sr * segment_length\n",
    "    segments = []\n",
    "    for start in range(0, len(data), segment_samples):\n",
    "        end = start + segment_samples\n",
    "        if end <= len(data):\n",
    "            segments.append(data[start:end])\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmented_data = []\n",
    "segmented_labels = []\n",
    "\n",
    "for data, label in zip(audio_data, audio_labels):\n",
    "    sr = librosa.get_samplerate(test_audio_files[0])\n",
    "    segments = segment_audio(data, sr)\n",
    "    segmented_data.extend(segments)\n",
    "    segmented_labels.extend([label] * len(segments))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction with customizable window size and hop length\n",
    "def extract_features(data, sr, n_mfcc=13, window_size=2048, hop_length=512):\n",
    "    mfccs = librosa.feature.mfcc(y=data, sr=sr, n_mfcc=n_mfcc, n_fft=window_size, hop_length=hop_length)\n",
    "    return np.mean(mfccs.T, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "custom_window_size = 1024\n",
    "custom_hop_length = 256\n",
    "\n",
    "for segment in segmented_data:\n",
    "    sr = librosa.get_samplerate(train_audio_files[0])\n",
    "    mfccs = extract_features(segment, sr, window_size=custom_window_size, hop_length=custom_hop_length)\n",
    "    features.append(mfccs)\n",
    "\n",
    "X_train = np.array(features)\n",
    "y_train = np.array(segmented_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1308, 13), (1308,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
