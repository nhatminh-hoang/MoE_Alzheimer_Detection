{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration\n",
    "\n",
    "This notebook is for exploring and visualizing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pylangacq\n",
    "\n",
    "from tqdm import tqdm\n",
    "import string\n",
    "punctuations = string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define PATH\n",
    "ADReSS2020_DATAPATH = \"../data/ADReSS-IS2020-data\"\n",
    "ADReSS2020_TRAINPATH = os.path.join(ADReSS2020_DATAPATH, \"train\")\n",
    "ADReSS2020_TESTPATH = os.path.join(ADReSS2020_DATAPATH, \"test\")\n",
    "\n",
    "TRANSCRIPT_NAME = \"transcription\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_par_utterances(file_path):\n",
    "    \"\"\"\n",
    "    Read a CHAT file and return a list of merged *PAR (and *INV) utterances.\n",
    "    This function merges continuation lines and removes trailing time codes.\n",
    "    \"\"\"\n",
    "    utterances = []\n",
    "    current_utterance = None\n",
    "\n",
    "    with open(file_path, 'r', encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.rstrip(\"\\n\")\n",
    "            # New utterance: lines starting with *PAR: or *INV:\n",
    "            if line.startswith(\"*PAR:\") or line.startswith(\"*INV:\"):\n",
    "                # If an utterance is in progress, finish and store it.\n",
    "                if current_utterance is not None:\n",
    "                    # Remove any trailing time code (text between two \u0015 symbols)\n",
    "                    current_utterance = re.sub(r'\u0015.*?\u0015', '', current_utterance).strip()\n",
    "                    utterances.append(current_utterance)\n",
    "                # Start a new utterance (remove the marker)\n",
    "                if line.startswith(\"*PAR:\"):\n",
    "                    current_utterance = line[len(\"*PAR:\"):].strip()\n",
    "                else:\n",
    "                    current_utterance = line[len(\"*INV:\"):].strip()\n",
    "            # Continuation lines (indented or containing a time code marker) are appended.\n",
    "            elif current_utterance is not None and ('\u0015' in line):\n",
    "                current_utterance += \" \" + line.strip()\n",
    "            # Otherwise, ignore the line.\n",
    "    \n",
    "    # Append the final utterance if one is in progress.\n",
    "    if current_utterance:\n",
    "        current_utterance = re.sub(r'\u0015.*?\u0015', '', current_utterance).strip()\n",
    "        utterances.append(current_utterance)\n",
    "    \n",
    "    return utterances\n",
    "\n",
    "def is_retracing(token):\n",
    "    \"\"\"\n",
    "    Determine if a token is a retracing token that should be merged with the previous token.\n",
    "    \n",
    "    Returns True for tokens matching patterns like:\n",
    "      - o(f)\n",
    "      - fallin(g)\n",
    "      - an(d)\n",
    "      - stealin(g)\n",
    "    (case-insensitive)\n",
    "    \n",
    "    But returns False for tokens such as (.), (..), or (...).\n",
    "    \"\"\"\n",
    "    pattern = re.compile(r'^(an|o|stealin|takin)\\([^)]*\\)$', re.IGNORECASE)\n",
    "    if pattern.match(token):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def merge_annotation_tokens(tokens, start_index):\n",
    "    \"\"\"\n",
    "    Merge tokens that are part of an annotation enclosed in brackets.\n",
    "    This function supports both square-bracket annotations (e.g., \"[+ exc]\") and\n",
    "    angle-bracket annotations (e.g., \"<walk with a>\").\n",
    "    \n",
    "    Returns a tuple of (merged_token, next_index).\n",
    "    \"\"\"\n",
    "    token = tokens[start_index]\n",
    "    if token.startswith('['):\n",
    "        closing = ']'\n",
    "    elif token.startswith('<'):\n",
    "        closing = '>'\n",
    "    else:\n",
    "        return token, start_index + 1\n",
    "\n",
    "    merged = token\n",
    "    i = start_index\n",
    "    # If the token already ends with the closing bracket, return it.\n",
    "    if merged.endswith(closing):\n",
    "        return merged, i + 1\n",
    "    i += 1\n",
    "    # Merge subsequent tokens until we find one that ends with the closing bracket.\n",
    "    while i < len(tokens) and not tokens[i].endswith(closing):\n",
    "        merged += \" \" + tokens[i]\n",
    "        i += 1\n",
    "    if i < len(tokens):\n",
    "        merged += \" \" + tokens[i]\n",
    "        i += 1\n",
    "    return merged, i\n",
    "\n",
    "def tokenize_and_merge(utterance, linking_token=\"{<miss_spell_token>}\"):\n",
    "    \"\"\"\n",
    "    Tokenize an utterance into tokens with the following custom behavior:\n",
    "    \n",
    "      - If a token is immediately followed by a retracing token \n",
    "        (e.g., 'o(f)', 'fallin(g)', 'an(d)', 'stealin(g)'), merge them into a single token \n",
    "        by concatenating with the linking_token.\n",
    "      - Merge bracketed annotations so that tokens like \"[+ exc]\" or \"[: overflowing]\" \n",
    "        and angle-bracket annotations like \"<walk with a>\" remain intact.\n",
    "    \n",
    "    Returns a list of tokens.\n",
    "    \"\"\"\n",
    "    tokens = utterance.split()\n",
    "    merged_tokens = []\n",
    "    i = 0\n",
    "    while i < len(tokens):\n",
    "        token = tokens[i]\n",
    "        \n",
    "        # If the token begins with '[' or '<' but does not end with the corresponding closing bracket,\n",
    "        # merge the entire annotation.\n",
    "        if (token.startswith('[') and not token.endswith(']')) or (token.startswith('<') and not token.endswith('>')):\n",
    "            merged_token, i = merge_annotation_tokens(tokens, i)\n",
    "            merged_tokens.append(merged_token)\n",
    "            continue\n",
    "\n",
    "        # Check if the next token is a retracing token.\n",
    "        # print(tokens[i+1]) if i + 1 < len(tokens) else None\n",
    "        if i + 1 < len(tokens) and is_retracing(str(tokens[i+1])):\n",
    "            print(tokens[i+1])\n",
    "            # Merge current token with the retracing token into a single token.\n",
    "            merged_tokens.append(token)\n",
    "            merged_tokens.append(linking_token + tokens[i+1])\n",
    "            i += 2\n",
    "            continue\n",
    "        \n",
    "        merged_tokens.append(token)\n",
    "        i += 1\n",
    "        \n",
    "    return merged_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/ADReSS-IS2020-data/train/transcription/cd/S118.cha\n",
      "['okay', \"let's\", 'try', 'something', 'different', 'okay', 'tell', 'me', 'what', 'you', 'see', 'in', 'that', 'picture', 'oh', \"there's\", 'a', 'cookie', 'jar', 'and', 'a', 'youngster', 'with', 'a', \"<I don't know what he got>\", '[//]', 'cookie', 'jar', 'and', 'the', 'boy', 'has', 'a', 'shirt', 'with', 'a', 'cookie', '&j', 'jar', 'too', 'I', 'guess', 'the', 'girl', 'has', 'one', 'too', 'a', 'jar', 'an(d)', \"that's\", 'the', 'stool', 'and', 'this', 'is', '&uh', 'with', 'a', 'kitchen', 'thing', '&k', 'dishes', '[+ gram]', 'and', 'this', 'is', 'water', 'somebody', 'spilled', '(.)', 'this', 'is', 'some', 'more', 'junk', '[+ es]', 'what', 'do', 'you', 'call', 'this', '[+ exc]', 'I', \"don't\", 'know', '[+ exc]', 'I', 'guess', \"it's\", 'another', 'for', 'the', '(.)', '&=sighs', '+...', 'I', \"don't\", 'know', \"what's\", 'hɑɹ@u', '[: x@n]', '[* n:uk]', 'in', 'there', '[+ jar]', '[+ exc]', 'the', 'tent@u', '[: x@n]', '[* n:uk]', 'very', 'interesting', '[+ jar]', \"what's\", 'going', 'over', 'here', 'Missus', 'Last_Name', 'what', 'do', 'you', 'see', 'going', 'on', 'over', 'there', '+<', 'oh', '&k', '(.)', 'I', \"don't\", 'know', '[+ exc]', \"she's\", 'looking', 'at', 'it', '[+ es]', 'I', \"don't\", 'know', 'what', '[+ exc]', 'that', 'the', \"kid's\", 'gonna', 'fall', 'off', 'the', 'stool', '[+ gram]', 'I', 'hope', 'he', 'does', '[+ exc]', '(.)', 'dumb', 'kids', '[+ exc]', '[+ gram]', 'what', 'else', 'is', 'going', 'on', 'over', 'here', 'oh', \"they're\", 'in', 'the', 'cookie', 'jar', 'over', 'here', 'can', 'you', 'look', 'over', 'here', 'now', 'what', 'do', 'you', 'see', 'going', 'on', 'over', 'here', 'oh', 'what', 'are', 'they', 'doing', '[+ exc]', 'I', \"don't\", 'know', '[+ exc]', \"they're\", 'spillin(g)', 'somethin(g)', 'good', 'and', '(.)', 'much', '[+ gram]', \"it's\", '[//]', \"they're\", 'doing', 'the', 'dishes', '(.)', 'dishes', 'they', 'are', '[+ gram]', 'the', \"boy's\", 'tryin(g)', 'to', 'fall', 'off', 'the', 'stool', 'and', \"she's\", 'tryin(g)', 'to', 'get', 'the', 'dishes', 'all', '&a', 'done', '(.)', 'okay']\n"
     ]
    }
   ],
   "source": [
    "# Read the \n",
    "transcript_path = os.path.join(ADReSS2020_TRAINPATH, TRANSCRIPT_NAME)\n",
    "reader = pylangacq.read_chat(transcript_path)\n",
    "\n",
    "# Replace with your actual CHAT file path.\n",
    "file_path = reader.file_paths()[80]\n",
    "print(file_path)\n",
    "\n",
    "# Read and merge *PAR utterances.\n",
    "utterances = read_par_utterances(file_path)\n",
    "\n",
    "# Tokenize and merge tokens from each utterance.\n",
    "all_tokens = []\n",
    "for utt in utterances:\n",
    "    tokens = tokenize_and_merge(utt)\n",
    "    all_tokens.extend([token for token in tokens if token not in list(punctuations)])\n",
    "\n",
    "print(all_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "okay: NO MATCH\n",
      "let's: NO MATCH\n",
      "try: NO MATCH\n",
      "something: NO MATCH\n",
      "different: NO MATCH\n",
      "okay: NO MATCH\n",
      "tell: NO MATCH\n",
      "me: NO MATCH\n",
      "what: NO MATCH\n",
      "you: NO MATCH\n",
      "see: NO MATCH\n",
      "in: NO MATCH\n",
      "that: NO MATCH\n",
      "picture: NO MATCH\n",
      "oh: NO MATCH\n",
      "there's: NO MATCH\n",
      "a: NO MATCH\n",
      "cookie: NO MATCH\n",
      "jar: NO MATCH\n",
      "and: NO MATCH\n",
      "a: NO MATCH\n",
      "youngster: NO MATCH\n",
      "with: NO MATCH\n",
      "a: NO MATCH\n",
      "<I don't know what he got>: NO MATCH\n",
      "[//]: NO MATCH\n",
      "cookie: NO MATCH\n",
      "jar: NO MATCH\n",
      "and: NO MATCH\n",
      "the: NO MATCH\n",
      "boy: NO MATCH\n",
      "has: NO MATCH\n",
      "a: NO MATCH\n",
      "shirt: NO MATCH\n",
      "with: NO MATCH\n",
      "a: NO MATCH\n",
      "cookie: NO MATCH\n",
      "&j: NO MATCH\n",
      "jar: NO MATCH\n",
      "too: NO MATCH\n",
      "I: NO MATCH\n",
      "guess: NO MATCH\n",
      "the: NO MATCH\n",
      "girl: NO MATCH\n",
      "has: NO MATCH\n",
      "one: NO MATCH\n",
      "too: NO MATCH\n",
      "a: NO MATCH\n",
      "jar: NO MATCH\n",
      "an(d): MATCH\n",
      "that's: NO MATCH\n",
      "the: NO MATCH\n",
      "stool: NO MATCH\n",
      "and: NO MATCH\n",
      "this: NO MATCH\n",
      "is: NO MATCH\n",
      "&uh: NO MATCH\n",
      "with: NO MATCH\n",
      "a: NO MATCH\n",
      "kitchen: NO MATCH\n",
      "thing: NO MATCH\n",
      "&k: NO MATCH\n",
      "dishes: NO MATCH\n",
      "[+ gram]: NO MATCH\n",
      "and: NO MATCH\n",
      "this: NO MATCH\n",
      "is: NO MATCH\n",
      "water: NO MATCH\n",
      "somebody: NO MATCH\n",
      "spilled: NO MATCH\n",
      "(.): NO MATCH\n",
      "this: NO MATCH\n",
      "is: NO MATCH\n",
      "some: NO MATCH\n",
      "more: NO MATCH\n",
      "junk: NO MATCH\n",
      "[+ es]: NO MATCH\n",
      "what: NO MATCH\n",
      "do: NO MATCH\n",
      "you: NO MATCH\n",
      "call: NO MATCH\n",
      "this: NO MATCH\n",
      "[+ exc]: NO MATCH\n",
      "I: NO MATCH\n",
      "don't: NO MATCH\n",
      "know: NO MATCH\n",
      "[+ exc]: NO MATCH\n",
      "I: NO MATCH\n",
      "guess: NO MATCH\n",
      "it's: NO MATCH\n",
      "another: NO MATCH\n",
      "for: NO MATCH\n",
      "the: NO MATCH\n",
      "(.): NO MATCH\n",
      "&=sighs: NO MATCH\n",
      "+...: NO MATCH\n",
      "I: NO MATCH\n",
      "don't: NO MATCH\n",
      "know: NO MATCH\n",
      "what's: NO MATCH\n",
      "hɑɹ@u: NO MATCH\n",
      "[: x@n]: NO MATCH\n",
      "[* n:uk]: NO MATCH\n",
      "in: NO MATCH\n",
      "there: NO MATCH\n",
      "[+ jar]: NO MATCH\n",
      "[+ exc]: NO MATCH\n",
      "the: NO MATCH\n",
      "tent@u: NO MATCH\n",
      "[: x@n]: NO MATCH\n",
      "[* n:uk]: NO MATCH\n",
      "very: NO MATCH\n",
      "interesting: NO MATCH\n",
      "[+ jar]: NO MATCH\n",
      "what's: NO MATCH\n",
      "going: NO MATCH\n",
      "over: NO MATCH\n",
      "here: NO MATCH\n",
      "Missus: NO MATCH\n",
      "Last_Name: NO MATCH\n",
      "what: NO MATCH\n",
      "do: NO MATCH\n",
      "you: NO MATCH\n",
      "see: NO MATCH\n",
      "going: NO MATCH\n",
      "on: NO MATCH\n",
      "over: NO MATCH\n",
      "there: NO MATCH\n",
      "+<: NO MATCH\n",
      "oh: NO MATCH\n",
      "&k: NO MATCH\n",
      "(.): NO MATCH\n",
      "I: NO MATCH\n",
      "don't: NO MATCH\n",
      "know: NO MATCH\n",
      "[+ exc]: NO MATCH\n",
      "she's: NO MATCH\n",
      "looking: NO MATCH\n",
      "at: NO MATCH\n",
      "it: NO MATCH\n",
      "[+ es]: NO MATCH\n",
      "I: NO MATCH\n",
      "don't: NO MATCH\n",
      "know: NO MATCH\n",
      "what: NO MATCH\n",
      "[+ exc]: NO MATCH\n",
      "that: NO MATCH\n",
      "the: NO MATCH\n",
      "kid's: NO MATCH\n",
      "gonna: NO MATCH\n",
      "fall: NO MATCH\n",
      "off: NO MATCH\n",
      "the: NO MATCH\n",
      "stool: NO MATCH\n",
      "[+ gram]: NO MATCH\n",
      "I: NO MATCH\n",
      "hope: NO MATCH\n",
      "he: NO MATCH\n",
      "does: NO MATCH\n",
      "[+ exc]: NO MATCH\n",
      "(.): NO MATCH\n",
      "dumb: NO MATCH\n",
      "kids: NO MATCH\n",
      "[+ exc]: NO MATCH\n",
      "[+ gram]: NO MATCH\n",
      "what: NO MATCH\n",
      "else: NO MATCH\n",
      "is: NO MATCH\n",
      "going: NO MATCH\n",
      "on: NO MATCH\n",
      "over: NO MATCH\n",
      "here: NO MATCH\n",
      "oh: NO MATCH\n",
      "they're: NO MATCH\n",
      "in: NO MATCH\n",
      "the: NO MATCH\n",
      "cookie: NO MATCH\n",
      "jar: NO MATCH\n",
      "over: NO MATCH\n",
      "here: NO MATCH\n",
      "can: NO MATCH\n",
      "you: NO MATCH\n",
      "look: NO MATCH\n",
      "over: NO MATCH\n",
      "here: NO MATCH\n",
      "now: NO MATCH\n",
      "what: NO MATCH\n",
      "do: NO MATCH\n",
      "you: NO MATCH\n",
      "see: NO MATCH\n",
      "going: NO MATCH\n",
      "on: NO MATCH\n",
      "over: NO MATCH\n",
      "here: NO MATCH\n",
      "oh: NO MATCH\n",
      "what: NO MATCH\n",
      "are: NO MATCH\n",
      "they: NO MATCH\n",
      "doing: NO MATCH\n",
      "[+ exc]: NO MATCH\n",
      "I: NO MATCH\n",
      "don't: NO MATCH\n",
      "know: NO MATCH\n",
      "[+ exc]: NO MATCH\n",
      "they're: NO MATCH\n",
      "spillin(g): NO MATCH\n",
      "somethin(g): NO MATCH\n",
      "good: NO MATCH\n",
      "and: NO MATCH\n",
      "(.): NO MATCH\n",
      "much: NO MATCH\n",
      "[+ gram]: NO MATCH\n",
      "it's: NO MATCH\n",
      "[//]: NO MATCH\n",
      "they're: NO MATCH\n",
      "doing: NO MATCH\n",
      "the: NO MATCH\n",
      "dishes: NO MATCH\n",
      "(.): NO MATCH\n",
      "dishes: NO MATCH\n",
      "they: NO MATCH\n",
      "are: NO MATCH\n",
      "[+ gram]: NO MATCH\n",
      "the: NO MATCH\n",
      "boy's: NO MATCH\n",
      "tryin(g): NO MATCH\n",
      "to: NO MATCH\n",
      "fall: NO MATCH\n",
      "off: NO MATCH\n",
      "the: NO MATCH\n",
      "stool: NO MATCH\n",
      "and: NO MATCH\n",
      "she's: NO MATCH\n",
      "tryin(g): NO MATCH\n",
      "to: NO MATCH\n",
      "get: NO MATCH\n",
      "the: NO MATCH\n",
      "dishes: NO MATCH\n",
      "all: NO MATCH\n",
      "&a: NO MATCH\n",
      "done: NO MATCH\n",
      "(.): NO MATCH\n",
      "okay: NO MATCH\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Build a pattern that matches our specific tokens.\n",
    "pattern = re.compile(r'^(an|o|stealin|takin)\\([^)]*\\)$', re.IGNORECASE)\n",
    "\n",
    "# Test tokens\n",
    "tokens = ['an(d)', 'o(f)', 'an(d)', 'stealin(g)', 'takin(g)', 'o(.)', 'an(abc)', 'something_else', '(...)']\n",
    "\n",
    "for token in all_tokens:\n",
    "    if pattern.match(token):\n",
    "        print(f\"{token}: MATCH\")\n",
    "    else:\n",
    "        print(f\"{token}: NO MATCH\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
